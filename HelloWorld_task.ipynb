{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlishaKK/Learn-AI/blob/main/HelloWorld_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Project 1: LangChain Hello World Project**\n",
        "\n",
        "This package incorporates Google Gemini AI into LangChain, providing enhanced natural language processing and advanced conversational AI features."
      ],
      "metadata": {
        "id": "HWHte9hDYYCf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tYHtqYzE43_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fcf5ae6-0141-43fe-d132-d0a0c0bf585e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatGoogleGenerativeAI: A LangChain wrapper for Google Gemini AI that integrates conversational AI and text generation capabilities into LangChain workflows.\n",
        "\n",
        "PromptTemplate: A LangChain utility that helps create dynamic and reusable text prompts for various AI tasks.\n",
        "\n",
        "LLMChain: A LangChain component that links a language model with a prompt, enabling the design of flexible and customizable AI task workflows.\n",
        "\n",
        "This code retrieves the Gemini API key securely stored in Google Colab, ensuring safe access to the Gemini API without hardcoding the key in your script."
      ],
      "metadata": {
        "id": "yNoRk1zpZTgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from google.colab import userdata\n",
        "api_key=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "UxMVn04l6GyY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code initializes the ChatGoogleGenerativeAI."
      ],
      "metadata": {
        "id": "QliORs5GbKNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm =ChatGoogleGenerativeAI(\n",
        "    api_key=api_key,\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0.7  # Adjust for creativity\n",
        ")"
      ],
      "metadata": {
        "id": "2YEaSi5xN0Yq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model=ChatGoogleGenerativeAI(api_key=api_key,model='gemini-2.0-flash-exp')"
      ],
      "metadata": {
        "id": "3hzHtrPb6S83"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prompt template establishes a framework for generating prompts, dynamically replacing `{question}` with user input to tailor the bot's responses."
      ],
      "metadata": {
        "id": "LcKlN3axbYIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"As an expert AI assistant with deep knowledge in AI engineering, please provide a thorough and insightful answer to the following question:\\n\\n{question}\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZRjdUuVVOKah"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A chain object designed to generate responses based on a given question."
      ],
      "metadata": {
        "id": "Ua6SCgVNb4sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "RPgupamAPCtP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.invoke(\"Hey how are yoyu dear bot?\")"
      ],
      "metadata": {
        "id": "1z6N81gp7vQW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a question, processes it using a predefined chain, and outputs the generated response."
      ],
      "metadata": {
        "id": "LSsBsMc-cBO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is LangChain?\"\n",
        "response = chain.run({\"question\": question})\n",
        "\n",
        "print(\"Answer:\", response)"
      ],
      "metadata": {
        "id": "wJD54XzwQxU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84722042-4b65-46a9-b005-af0209293e81"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Okay, let's dive deep into LangChain. As an expert AI assistant with deep knowledge in AI engineering, I can provide you with a thorough and insightful explanation of what LangChain is, its core concepts, its architecture, its benefits, and its limitations.\n",
            "\n",
            "**LangChain: More Than Just a Library, It's a Framework for Building LLM-Powered Applications**\n",
            "\n",
            "At its core, LangChain is an **open-source framework** designed to simplify the process of building applications that leverage the power of large language models (LLMs). It's not just a simple library with a few functions; it's a comprehensive toolkit that provides a structured way to orchestrate and interact with LLMs, external data sources, and other tools. Think of it as a scaffolding that helps you create sophisticated AI applications without getting bogged down in the low-level complexities.\n",
            "\n",
            "**Key Concepts and Components of LangChain:**\n",
            "\n",
            "LangChain's power comes from its modular and well-defined components. Here are the key concepts:\n",
            "\n",
            "1. **Models:** This is where you interface with the LLMs themselves. LangChain supports a wide variety of models, including:\n",
            "    * **OpenAI (GPT-3, GPT-4, etc.)**\n",
            "    * **Hugging Face Hub Models**\n",
            "    * **Cohere**\n",
            "    * **Anthropic (Claude)**\n",
            "    * **Llama models (via various integrations)**\n",
            "    * **And many more...**\n",
            "    LangChain provides a unified API for interacting with these models, abstracting away the specific nuances of each provider.\n",
            "\n",
            "2. **Prompts & Prompt Templates:** Crafting effective prompts is crucial for getting the most out of LLMs. LangChain provides:\n",
            "    * **Prompt Templates:** Reusable structures for creating prompts with dynamic variables.\n",
            "    * **Prompt Management:** Tools to manage and track your prompts.\n",
            "    * **Example Selectors:** Mechanisms to choose relevant examples to include in your prompts for better few-shot learning.\n",
            "\n",
            "3. **Chains:** The heart of LangChain's functionality. Chains allow you to sequence calls to LLMs and other tools. This enables complex workflows, such as:\n",
            "    * **LLM Chain:** Simple sequence of calling a language model.\n",
            "    * **Sequential Chain:** Chaining multiple LLM calls, where the output of one is the input of the next.\n",
            "    * **Router Chain:** Dynamically routes the input to different chains based on the task.\n",
            "    * **Transform Chain:** Modifies the input text before passing it to the next step.\n",
            "\n",
            "4. **Indexes (Data Connection):** LLMs are powerful, but they don't inherently know about your private data. LangChain provides tools to connect LLMs to external data sources, including:\n",
            "    * **Document Loaders:** Load data from various formats (PDFs, text files, web pages, etc.).\n",
            "    * **Text Splitters:** Split large documents into smaller chunks that fit within the LLM's context window.\n",
            "    * **Vector Stores:** Store document embeddings (numerical representations of the text) for efficient retrieval (e.g., using FAISS, ChromaDB).\n",
            "    * **Retrievers:** Retrieve relevant documents based on user queries, enabling the LLM to access external knowledge.\n",
            "\n",
            "5. **Agents:** Agents take chains to the next level by allowing the LLM to decide which tools to use and when. Agents can:\n",
            "    * **Reason about the best course of action.**\n",
            "    * **Use tools (e.g., search engines, calculators, databases).**\n",
            "    * **Iteratively refine their answers based on the tool outputs.**\n",
            "    * **Provide a more interactive and flexible experience.**\n",
            "\n",
            "6. **Memory:** LLMs are stateless by default. LangChain's memory module allows you to:\n",
            "    * **Maintain context across multiple interactions.**\n",
            "    * **Store conversation history.**\n",
            "    * **Implement different memory strategies (e.g., buffer memory, summary memory).**\n",
            "\n",
            "7. **Callbacks:** These allow you to monitor the progress of your chains and agents, enabling:\n",
            "    * **Logging and debugging.**\n",
            "    * **Visualization of the execution flow.**\n",
            "    * **Integration with other systems.**\n",
            "\n",
            "8. **Tools:** LangChain integrates with a wide range of external tools that can extend the capabilities of LLMs, including:\n",
            "    * **Search Engines (Google, Bing)**\n",
            "    * **Calculators**\n",
            "    * **APIs**\n",
            "    * **Databases**\n",
            "    * **File Systems**\n",
            "\n",
            "**Architecture of LangChain:**\n",
            "\n",
            "LangChain's architecture is designed to be modular and extensible. It's organized around a few key layers:\n",
            "\n",
            "* **Core Abstractions:** These are the base classes for models, prompts, chains, etc.\n",
            "* **Integrations:** This layer connects LangChain to various LLMs, data sources, vector stores, and tools.\n",
            "* **Utilities:** This includes helper functions for tasks like logging, debugging, and prompt management.\n",
            "* **Use Cases:** This layer provides examples and templates for common use cases, such as chatbots, question answering, and summarization.\n",
            "\n",
            "**Benefits of Using LangChain:**\n",
            "\n",
            "* **Rapid Prototyping:** LangChain simplifies the process of building LLM applications, allowing you to quickly experiment and iterate on your ideas.\n",
            "* **Modularity and Reusability:** The modular architecture allows you to mix and match components to build complex workflows.\n",
            "* **Flexibility and Extensibility:** You can easily integrate custom models, tools, and data sources.\n",
            "* **Simplified Complexity:** LangChain handles many of the low-level complexities of working with LLMs, allowing you to focus on the application logic.\n",
            "* **Active Community and Support:** LangChain has a vibrant open-source community that provides support, resources, and contributions.\n",
            "* **Standardization:** LangChain provides a consistent interface for interacting with different LLMs, reducing the effort required to switch between providers.\n",
            "\n",
            "**Limitations of LangChain:**\n",
            "\n",
            "* **Complexity:** While LangChain simplifies many aspects of LLM development, it can still be complex to learn and master.\n",
            "* **Abstraction Overhead:** The abstraction layer can sometimes make it harder to debug or understand the underlying processes.\n",
            "* **Rapid Development:** The framework is still under rapid development, which means that APIs and features can change frequently.\n",
            "* **Performance Overhead:** Using chains and agents can sometimes add a performance overhead compared to directly interacting with the LLM.\n",
            "* **Not a Magic Bullet:** LangChain is a tool, and it still requires careful design and prompting to get good results. You still need to understand the limitations of LLMs themselves.\n",
            "\n",
            "**Use Cases of LangChain:**\n",
            "\n",
            "LangChain can be used to build a wide variety of applications, including:\n",
            "\n",
            "* **Chatbots and Conversational AI:** Build interactive chatbots that can answer questions, provide information, and perform tasks.\n",
            "* **Question Answering Systems:** Create systems that can answer complex questions based on large amounts of data.\n",
            "* **Text Summarization and Generation:** Summarize long documents or generate new text based on specific prompts.\n",
            "* **Code Generation and Assistance:** Help developers write code by providing suggestions, generating snippets, and debugging code.\n",
            "* **Data Analysis and Extraction:** Extract insights from unstructured data sources.\n",
            "* **Personalized Learning Platforms:** Create adaptive learning experiences that tailor content to individual needs.\n",
            "* **Content Creation Tools:** Build tools that can help writers generate ideas, improve their writing, and create different forms of content.\n",
            "\n",
            "**In Summary:**\n",
            "\n",
            "LangChain is a powerful and versatile framework that significantly simplifies the process of building sophisticated applications powered by large language models. It provides a modular and extensible architecture, along with a rich set of tools and integrations. While it has a learning curve and some limitations, its benefits make it an invaluable tool for AI engineers and developers looking to leverage the power of LLMs. It empowers you to go beyond simple prompt engineering and build truly intelligent and interactive applications.\n",
            "\n",
            "Remember that LangChain is constantly evolving, so staying updated with the latest releases and community discussions is crucial for maximizing its potential.\n"
          ]
        }
      ]
    }
  ]
}